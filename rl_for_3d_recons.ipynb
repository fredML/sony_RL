{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "os.chdir('/mnt/diskSustainability/frederic/sony_RL/sony_RL/base_functions')\n",
    "from dm_env_sphere import SphereEnv\n",
    "from utils import get_mask_background\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "import optuna\n",
    "from acme import specs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sphere creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyscad as ops\n",
    "import subprocess\n",
    "import urllib\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "def scad_to_stl_to_obj(path_k, obj_name):\n",
    "    # transform scad to stl\n",
    "    subprocess.run(['/usr/bin/openscad','-o', os.path.join(path_k, obj_name + '.stl'), os.path.join(path_k, obj_name + '.scad')])\n",
    "\n",
    "    # transform stl to obj using blender\n",
    "    localhost = \"http://localhost:5000/\" \n",
    "    url_part = \"stlobj?stl=\" + os.path.join(path_k, obj_name + '.stl') +\"&obj=\" + os.path.join(path_k, obj_name + '.obj') \n",
    "    + \"&forward=X\" + \"&up=Z\"\n",
    "    urllib.request.urlopen(localhost + url_part).read()\n",
    "\n",
    "def random_sphere_creation(n_spheres, n_holes, path):\n",
    "    for k in range (n_spheres):\n",
    "        theta = np.random.randint(0, 90, n_holes)\n",
    "        phi = np.random.randint(0, 360, n_holes)\n",
    "        s = ops.Sphere(r=5,_fn=100)\n",
    "        c = ops.Cylinder(r=0.5,h=12,center=True, _fn=100)\n",
    "        c = c.rotate([0,theta[0],phi[0]])\n",
    "        d = ops.Difference()\n",
    "        d.append(s)\n",
    "        d.append(c)\n",
    "        for i in range (1,n_holes):\n",
    "            c = ops.Cylinder(r=0.5,h=12,center=True, _fn=100)\n",
    "            c = c.rotate([0,theta[i],phi[i]])\n",
    "            temp_d = d\n",
    "            d = ops.Difference()\n",
    "            d.append(temp_d)\n",
    "            d.append(c)\n",
    "\n",
    "        obj_name = f'random_sphere_{k}'\n",
    "        \n",
    "        path_k = os.path.join(path, obj_name)\n",
    "        if not os.path.exists(path_k):\n",
    "            os.mkdir(path_k)\n",
    "        d.write(os.path.join(path_k, obj_name + '.scad'))\n",
    "        with open(os.path.join(path_k, obj_name + '.json'), 'w') as f:\n",
    "            json.dump(list(zip(theta*np.pi/180,phi*np.pi/180)), f, cls=NpEncoder)\n",
    "        \n",
    "        scad_to_stl_to_obj(path_k, obj_name)\n",
    "\n",
    "        subprocess.run(['cp','/mnt/diskSustainability/frederic/scanner-gym_models_v2/sphere_hole/camera_model.json',\n",
    "                    path_k])\n",
    "        subprocess.run(['cp','/mnt/diskSustainability/frederic/scanner-gym_models_v2/sphere_hole/bbox_general.json',\n",
    "                        path_k])\n",
    "        subprocess.run(['cp','/mnt/diskSustainability/frederic/scanner-gym_models_v2/sphere_hole/params.json',\n",
    "                        path_k])\n",
    "        \n",
    "\n",
    "def random_plant_creation(n_plants, n_branches, path):\n",
    "    for k in range (n_plants):\n",
    "        theta = np.random.randint(0, 90, n_branches)\n",
    "        phi = np.random.randint(0, 360, n_branches)\n",
    "        u = ops.Union()\n",
    "        for i in range (n_branches):\n",
    "            if i == 0:\n",
    "                c = ops.Cylinder(r=0.5, h=12, center=True, _fn=10)\n",
    "            else:\n",
    "                c = ops.Cylinder(r=0.5, h=6, _fn=10) \n",
    "            d = ops.Circle(r=1, _fn=4)\n",
    "            d = d.linear_extrude(height=1,center=True, _fn=10)\n",
    "            d = d.rotate([0,90,0])\n",
    "            d = d.translate([0,0,7.01])\n",
    "            e = c+d\n",
    "            e = e.rotate([0, theta[i], phi[i]])\n",
    "            u.append(e)\n",
    "        \n",
    "        obj_name = f'random_plant_{k}'\n",
    "        \n",
    "        path_k = os.path.join(path, obj_name)\n",
    "        if not os.path.exists(path_k):\n",
    "            os.mkdir(path_k)\n",
    "        u.write(os.path.join(path_k, obj_name + '.scad'))\n",
    "        with open(os.path.join(path_k, obj_name + '.json'), 'w') as f:\n",
    "            json.dump(list(zip(theta*np.pi/180,phi*np.pi/180)), f, cls=NpEncoder)\n",
    "        \n",
    "        scad_to_stl_to_obj(path_k, obj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_plant_creation(10, 3, '/mnt/diskSustainability/frederic/scanner-gym_models_v2/random_plants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# environment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load('/mnt/diskSustainability/frederic/scanner-gym_models_v2/sphere_hole/ground_truth_volumes/gt_0.npy')\n",
    "\n",
    "x,y,z = np.where(gt==-1)\n",
    "\n",
    "mask = ((y==12) & (z==12)) | ((y==12) & (z==13)) | ((y==13) & (z==12)) | ((y==13) & (z==13))\n",
    "mask = mask & (x>4) & (x<21)\n",
    "mask1 = ((y==z) & (x==12)) | ((y==z) & (x==13))\n",
    "mask1 = mask1 & (y>4) & (y<21)\n",
    "mask2 = ((y==25-z) & (x==12)) | ((y==25-z) & (x==13))\n",
    "mask2 = mask2 & (y>4) & (y<21)\n",
    "\n",
    "mask = mask | mask1 | mask2\n",
    "\n",
    "voxel_weights = np.zeros((25,25,25))\n",
    "\n",
    "for i in range (len(x[mask])):\n",
    "    voxel_weights[x[mask][i],y[mask][i],z[mask][i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_holes = []\n",
    "objects_path = []\n",
    "object_name = []\n",
    "\n",
    "for k in range (10):\n",
    "    obj = f'random_plant_{k}'\n",
    "    path_k = f'/mnt/diskSustainability/frederic/scanner-gym_models_v2/random_plants/' + obj\n",
    "    objects_path.append(path_k)\n",
    "    object_name.append(obj + f'.obj')\n",
    "    list_holes.append(json.load(open(path_k + '/' + obj + '.json')))\n",
    "\n",
    "env = SphereEnv(objects_path, object_name, list_holes=list_holes, rmax_T=100, max_T=100000, theta_n_positions=90)\n",
    "env_test = SphereEnv(objects_path, object_name, list_holes=list_holes, rmax_T=100, max_T=100000, theta_n_positions=90)\n",
    "ts = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    ts = env.reset(obj=object_name[k])\n",
    "    print(env.current_obj)\n",
    "    M = env.current_spc.neigh_ijk\n",
    "    \n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(x=M[:,0],y=M[:,1],z=M[:,2],mode='markers',showlegend=False))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a gt model by taking many views on a spherical grid. Get the maximum reward obtained (which can be different from 1) for further normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range (10):\n",
    "    ts = env.reset(obj=k)\n",
    "    for theta in range (env.theta_n_positions):\n",
    "        for phi in range (env.phi_n_positions):\n",
    "            ts = env.step_angle((theta+1)*np.pi/(env.theta_n_positions), phi*2*np.pi/env.phi_n_positions)\n",
    "            if env.done:\n",
    "                print('done')\n",
    "\n",
    "    path_k = f'/mnt/diskSustainability/frederic/scanner-gym_models_v2/random_plants/random_plant_{k}/'\n",
    "    l = json.load(open(path_k + 'params.json')) # do it only once per object to set the maximum reward value\n",
    "    if 'rmax_inf' not in l['train'].keys():\n",
    "        l['train']['rmax_inf'] = env.total_reward\n",
    "        if env.total_reward == 0:\n",
    "            print(0)\n",
    "        with open(path_k + 'params.json', 'w') as f:\n",
    "            json.dump(l, f)\n",
    "    np.save(path_k + 'gt', env.current_spc.last_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE pretraining using Optuna for hyperparameter search. \n",
    "# Several encoder architecture : Simple encoder, ResNet, VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = []\n",
    "ts = env.reset()\n",
    "for theta in np.linspace(np.pi/8,np.pi/2,5):\n",
    "    for phi in np.linspace(0,2*np.pi,100):\n",
    "        ts = env.step_angle(theta, phi)\n",
    "        obs.append(env.canny[None])\n",
    "obs = np.concatenate(obs)\n",
    "obs = obs*1.\n",
    "var = np.var(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.8'\n",
    "\n",
    "os.chdir('/mnt/diskSustainability/frederic/sony_RL/sony_RL/sac') \n",
    "import vae\n",
    "import vqvae\n",
    "os.chdir(path)\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_linear_epochs = 5000\n",
    "num_batches = 1000\n",
    "num_epochs = 3000\n",
    "num_factors = 2\n",
    "batch_size = 16\n",
    "batch_size_disantanglement = 64\n",
    "input_channels = output_channels = 1\n",
    "input_size = 128\n",
    "filter_sizes = [16,32,64,128]\n",
    "final_activation = jax.jit(lambda s:s)\n",
    "\n",
    "def objective_vae(trial):\n",
    "\n",
    "    seed = np.random.randint(100)\n",
    "\n",
    "    latent_dim = trial.suggest_int('latent_dim', 3, 30)\n",
    "    lambda_kl = trial.suggest_float('lambda_kl', 1e-8, 1, log=True)\n",
    "\n",
    "    def classic_vae(s, is_training):\n",
    "        return vae.VAE(input_size, latent_dim, filter_sizes, output_channels, final_activation, coord_conv=True)(s, is_training)\n",
    "\n",
    "    vae_init, vae_apply  = hk.without_apply_rng(hk.transform_with_state(classic_vae))\n",
    "    vae_apply_jit = jax.jit(vae_apply, static_argnums=3)\n",
    "    params_vae, bn_vae_state = vae_init(jax.random.PRNGKey(seed), np.random.uniform(0, 1, (1,input_size,input_size,input_channels)), True)\n",
    "    optimizer_vae = optax.radam(5e-4)\n",
    "    opt_vae_state = optimizer_vae.init(params_vae)\n",
    "\n",
    "    @jax.jit\n",
    "    def loss_ae(params, bn_state, obs):\n",
    "\n",
    "        aux, bn_state = vae_apply_jit(params, bn_state, obs, True)\n",
    "        reconst, latent, mu, log_var = aux\n",
    "\n",
    "        # MSE for reconstruction errors.\n",
    "        loss_reconst = jnp.square(obs - reconst).mean()\n",
    "        loss_reconst = loss_reconst/var\n",
    "\n",
    "        loss_kl = vae.kl_gaussian(mu, log_var)\n",
    "        loss_kl = loss_kl * lambda_kl\n",
    "        \n",
    "        return loss_reconst + loss_kl, (loss_reconst, loss_kl, bn_state)\n",
    "\n",
    "    @jax.jit\n",
    "    def update(params, opt_state, bn_state, obs):\n",
    "\n",
    "        (loss, aux), grad = jax.value_and_grad(loss_ae, has_aux=True)(params, bn_state, obs)\n",
    "        updates, new_opt_state = optimizer_vae.update(grad, opt_state)\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "        return new_params, new_opt_state, loss, aux\n",
    "        \n",
    "    losses = []\n",
    "    \n",
    "    for _ in range(num_epochs):\n",
    "\n",
    "        idx = np.random.choice(len(obs), batch_size, replace=False)\n",
    "        batch_obs = jnp.array(obs[idx])\n",
    "        params_vae, opt_vae_state, loss, aux = update(params_vae, opt_vae_state, bn_vae_state, batch_obs)\n",
    "        loss_reconst, loss_kl, bn_vae_state = aux\n",
    "        losses.append([loss_reconst.item(), loss_kl.item(), loss.item()])\n",
    "\n",
    "    losses = np.array(losses)\n",
    "\n",
    "    #calculate disantanglement metric\n",
    "    X, y = vae.disantanglement_data(vae_apply_jit, params_vae, bn_vae_state, num_batches, batch_size_disantanglement, num_factors, input_size, input_size)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "    ax[0].plot(losses[:,0],label='reconst')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(losses[:,1],label='kl')\n",
    "    ax[1].legend()\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "    idx = np.random.choice(len(obs))\n",
    "    ax[0].imshow(obs[idx], cmap='gray')\n",
    "    aux, _ = vae_apply_jit(params_vae, bn_vae_state, obs[idx][None], False)\n",
    "    reconst, latent, mu, log_var = aux\n",
    "    ax[1].imshow(reconst[0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    '''plt.figure(figsize=(15,3))\n",
    "    plt.plot(A)\n",
    "\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.plot(L)'''\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # Create a new study.\n",
    "study.optimize(objective_vae, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_vqvae(trial):\n",
    "\n",
    "    input_size = 128\n",
    "    num_epochs = 3000\n",
    "    batch_size = 16\n",
    "    decay = 0.99\n",
    "    input_channels = output_channels = 1\n",
    "    seed = np.random.randint(100)\n",
    "    \n",
    "    num_hiddens = 32\n",
    "    num_residual_hiddens = 32\n",
    "    num_residual_layers = 2\n",
    "\n",
    "    latent_dim = trial.suggest_int('latent_dim', 3, 10)\n",
    "    commitment_cost = trial.suggest_float('commitment_cost', 1e-5, 1e2, log=True)\n",
    "    #lambda_decoder = trial.suggest_float('lambda_decoder', 1e-8, 1e-2, log=True)\n",
    "    #num_embeddings = trial.suggest_int('num_embeddings', 64, 512)\n",
    "    num_embeddings = 512\n",
    "\n",
    "    def VQVAE(s, is_training):\n",
    "        return vqvae.VQVAE(latent_dim, num_embeddings, num_hiddens, num_residual_layers, num_residual_hiddens, commitment_cost, decay, output_channels)(s, is_training)\n",
    "\n",
    "    vae_init, vae_apply  = hk.without_apply_rng(hk.transform_with_state(VQVAE))\n",
    "    vae_apply_jit = jax.jit(vae_apply, static_argnums=3)\n",
    "    params_vae, bn_vae_state = vae_init(jax.random.PRNGKey(seed), np.random.uniform(0, 1, (1,input_size,input_size,input_channels)), True)\n",
    "    optimizer_vae = optax.adam(5e-4)\n",
    "    opt_vae_state = optimizer_vae.init(params_vae)\n",
    "\n",
    "    @jax.jit\n",
    "    def loss_ae(params, bn_state, obs):\n",
    "\n",
    "        vq_output, bn_state = vae_apply_jit(params, bn_state, obs, True)\n",
    "        vq_loss = vq_output['vq_loss']\n",
    "        loss_reconst = vq_output['recon_error']\n",
    "        loss_reconst = loss_reconst/var\n",
    "\n",
    "        '''decoder_params = {k:params[k] for k in params.keys() if 'decoder' in k}\n",
    "        leaves, _ = jax.tree_flatten(decoder_params)\n",
    "        loss_decoder = lambda_decoder * jnp.linalg.norm(jax.flatten_util.ravel_pytree(leaves)[0])**2'''\n",
    "        loss_latent = 0\n",
    "        loss_decoder = 0\n",
    "\n",
    "        return vq_loss + loss_reconst + loss_decoder + loss_latent, (vq_loss, loss_reconst, loss_decoder, loss_latent, bn_state)\n",
    "    \n",
    "    def update(params, opt_state, bn_state, obs):\n",
    "        (loss, aux), grad = jax.value_and_grad(loss_ae, has_aux=True)(params, bn_state, obs)\n",
    "        updates, new_opt_state = optimizer_vae.update(grad, opt_state)\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "        return new_params, new_opt_state, loss, aux\n",
    "\n",
    "    update_jit = jax.jit(update)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for k in range(num_epochs):\n",
    "\n",
    "        idx = np.random.choice(len(obs), batch_size)\n",
    "        batch_obs = jnp.array(obs[idx])\n",
    "        params_vae, opt_vae_state, loss, aux = update_jit(params_vae, opt_vae_state, bn_vae_state, batch_obs)\n",
    "        vq_loss, loss_reconst, loss_decoder, loss_latent, bn_vae_state = aux\n",
    "        losses.append([loss_reconst.item(), vq_loss.item(), loss_decoder.item(), loss_latent.item(), loss.item()])\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    fig, ax = plt.subplots(2,2,figsize=(15,5))\n",
    "    ax[0,0].plot(losses[:,0],label='reconst')\n",
    "    ax[0,0].legend()\n",
    "    ax[0,1].plot(losses[:,1],label='vq')\n",
    "    ax[0,1].legend()\n",
    "    ax[1,0].plot(losses[:,2],label='decoder')\n",
    "    ax[1,0].legend()\n",
    "    ax[1,1].plot(losses[:,3],label='latent')\n",
    "    ax[1,1].legend()\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "    idx = np.random.choice(len(obs))\n",
    "    ax[0].imshow(obs[idx], cmap='gray')\n",
    "    vq_output, _ = vae_apply_jit(params_vae, bn_vae_state, obs[idx][None], False)\n",
    "    reconst = vq_output['x_recon']\n",
    "    ax[1].imshow(reconst[0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    return losses[-1,0]\n",
    "\n",
    "study = optuna.create_study()  # Create a new study.\n",
    "study.optimize(objective_vqvae, n_trials=15, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_vae(trial):\n",
    "\n",
    "    input_size = 128\n",
    "    num_epochs = 3000\n",
    "    batch_size = 16\n",
    "    seed = np.random.randint(100)\n",
    "    filter_sizes = [16,32,64,128]\n",
    "    input_channels = output_channels = 1\n",
    "\n",
    "    latent_dim = trial.suggest_int('latent_dim', 3, 40)\n",
    "    lambda_kl = trial.suggest_float('lambda_kl', 1e-8, 1e-4, log=True)\n",
    "    temp = trial.suggest_float('temp', 1e-3, 1e3, log=True)\n",
    "    prior =  trial.suggest_float('prior', 1e-3, 1e-1, log=True)\n",
    "    num_classes = 2 \n",
    "    final_activation = jax.jit(lambda s:s)\n",
    "    #lambda_decoder = trial.suggest_float('lambda_decoder', 1e-8, 1e-5, log=True)\n",
    "    #lambda_latent = trial.suggest_float('lambda_latent', 1e-8, 1e-5, log=True)\n",
    "\n",
    "    def cat_vae(s, is_training, T):\n",
    "        return vae.CatVAE(input_size, latent_dim, num_classes, filter_sizes, output_channels, final_activation)(s, is_training, T)\n",
    "\n",
    "    vae_init, vae_apply  = hk.without_apply_rng(hk.transform_with_state(cat_vae))\n",
    "    vae_apply_jit = jax.jit(vae_apply, static_argnums=3)\n",
    "    params_vae, bn_vae_state = vae_init(jax.random.PRNGKey(seed), np.random.uniform(0, 1, (1,input_size,input_size,input_channels)), True, temp)\n",
    "    optimizer_vae = optax.radam(5e-4)\n",
    "    opt_vae_state = optimizer_vae.init(params_vae)\n",
    "\n",
    "    @jax.jit\n",
    "    def loss_ae(params, bn_state, obs, T, eps = 1e-7):\n",
    "\n",
    "        aux, bn_state = vae_apply_jit(params, bn_state, obs, True, T)\n",
    "        reconst, latent, q = aux\n",
    "        q_p = jax.nn.softmax(q, axis=-1)\n",
    "\n",
    "        # MSE for reconstruction errors.\n",
    "        loss_reconst = jnp.square(obs - reconst).mean()\n",
    "        loss_reconst = loss_reconst/var\n",
    "\n",
    "        loss_decoder = 0\n",
    "        loss_latent = 0\n",
    "\n",
    "        h1 = q_p * jnp.log(q_p + eps)\n",
    "\n",
    "        # Cross entropy with the categorical distribution\n",
    "        h2 = q_p * jnp.log(prior + eps)\n",
    "        loss_kl = jnp.mean(jnp.sum(h1 - h2, axis =(1,2)), axis=0)\n",
    "        loss_kl = lambda_kl*loss_kl\n",
    "       \n",
    "        return loss_reconst + loss_kl + loss_decoder + loss_latent, (loss_reconst, loss_kl, loss_decoder, loss_latent, bn_state)\n",
    "    \n",
    "    def update(params, opt_state, bn_state, obs, T):\n",
    "\n",
    "        (loss, aux), grad = jax.value_and_grad(loss_ae, has_aux=True)(params, bn_state, obs, T)\n",
    "        updates, new_opt_state = optimizer_vae.update(grad, opt_state)\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "        return new_params, new_opt_state, loss, aux\n",
    "\n",
    "    update_jit = jax.jit(update)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for k in range(1,num_epochs+1):\n",
    "        idx = np.random.choice(len(obs), batch_size)\n",
    "        batch_obs = jnp.array(obs[idx])\n",
    "        params_vae, opt_vae_state, loss, aux = update_jit(params_vae, opt_vae_state, bn_vae_state, batch_obs, temp)\n",
    "        loss_reconst, loss_kl, loss_decoder, loss_latent, bn_vae_state = aux\n",
    "        losses.append([loss_reconst.item(), loss_kl.item(), loss_decoder.item(), loss_latent.item(), loss.item()])\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    fig, ax = plt.subplots(2,2,figsize=(15,5))\n",
    "    ax[0,0].plot(losses[:,0],label='reconst')\n",
    "    ax[0,0].legend()\n",
    "    ax[0,1].plot(losses[:,1],label='kl')\n",
    "    ax[0,1].legend()\n",
    "    ax[1,0].plot(losses[:,2],label='decoder')\n",
    "    ax[1,0].legend()\n",
    "    ax[1,1].plot(losses[:,3],label='latent')\n",
    "    ax[1,1].legend()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "    idx = np.random.choice(len(obs))\n",
    "    ax[0].imshow(obs[idx], cmap='gray')\n",
    "    aux, _ = vae_apply_jit(params_vae, bn_vae_state, obs, False, temp)\n",
    "    reconst, latent, q_p = aux\n",
    "    ax[1].imshow(reconst[0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    return losses[-1,0]\n",
    "\n",
    "study = optuna.create_study()  # Create a new study.\n",
    "study.optimize(objective_vae, n_trials=30, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "num_epochs = 5000\n",
    "batch_size = 16\n",
    "seed = np.random.randint(100)\n",
    "filter_sizes = [16,32,64,128]\n",
    "input_channels = output_channels = 1\n",
    "final_activation = jax.jit(lambda s:s)\n",
    "\n",
    "latent_dim = 14\n",
    "\n",
    "def classic_vae(s, is_training):\n",
    "    return vae.VAE(input_size, latent_dim, filter_sizes, output_channels, final_activation, coord_conv=True)(s, is_training)\n",
    "\n",
    "vae_init, vae_apply  = hk.without_apply_rng(hk.transform_with_state(classic_vae))\n",
    "vae_apply_jit = jax.jit(vae_apply, static_argnums=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "num_epochs = 3000\n",
    "batch_size = 16\n",
    "decay = 0.99\n",
    "input_channels = output_channels = 1\n",
    "seed = np.random.randint(100)\n",
    "\n",
    "num_hiddens = 32\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 2\n",
    "\n",
    "latent_dim = 5\n",
    "commitment_cost = 0.00044\n",
    "\n",
    "num_embeddings = 512\n",
    "\n",
    "def VQVAE(s, is_training):\n",
    "    return vqvae.VQVAE(latent_dim, num_embeddings, num_hiddens, num_residual_layers, num_residual_hiddens, commitment_cost, decay, output_channels)(s, is_training)\n",
    "\n",
    "vae_init, vae_apply  = hk.without_apply_rng(hk.transform_with_state(VQVAE))\n",
    "vae_apply_jit = jax.jit(vae_apply, static_argnums=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain the VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_kl = 9.21e-5\n",
    "\n",
    "params_vae, bn_vae_state = vae_init(jax.random.PRNGKey(seed), np.random.uniform(0, 1, (1,input_size,input_size,input_channels)), True)\n",
    "optimizer_vae = optax.radam(5e-4)\n",
    "opt_vae_state = optimizer_vae.init(params_vae)\n",
    "\n",
    "@jax.jit\n",
    "def loss_ae(params, bn_state, obs):\n",
    "\n",
    "    aux, bn_state = vae_apply_jit(params, bn_state, obs, True)\n",
    "    reconst, latent, mu, log_var = aux\n",
    "\n",
    "    # MSE for reconstruction errors.\n",
    "    loss_reconst = jnp.square(obs - reconst).mean()\n",
    "    loss_reconst = loss_reconst/var\n",
    "\n",
    "    loss_decoder = 0\n",
    "    loss_latent = 0\n",
    "\n",
    "    loss_kl = vae.kl_gaussian(mu, log_var)\n",
    "    loss_kl = loss_kl * lambda_kl\n",
    "    \n",
    "    return loss_reconst + loss_kl + loss_decoder + loss_latent, (loss_reconst, loss_kl, loss_decoder, loss_latent, bn_state)\n",
    "\n",
    "def update(params, opt_state, bn_state, obs):\n",
    "\n",
    "    (loss, aux), grad = jax.value_and_grad(loss_ae, has_aux=True)(params, bn_state, obs)\n",
    "    updates, new_opt_state = optimizer_vae.update(grad, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "    return new_params, new_opt_state, loss, aux\n",
    "\n",
    "update_jit = jax.jit(update)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for k in range(num_epochs):\n",
    "\n",
    "    idx = np.random.choice(len(obs), batch_size)\n",
    "    batch_obs = jnp.array(obs[idx])\n",
    "    params_vae, opt_vae_state, loss, aux = update_jit(params_vae, opt_vae_state, bn_vae_state, batch_obs)\n",
    "    loss_reconst, loss_kl, loss_decoder, loss_latent, bn_vae_state = aux\n",
    "    losses.append([loss_reconst.item(), loss_kl.item(), loss_decoder.item(), loss_latent.item(), loss.item()])\n",
    "\n",
    "losses = np.array(losses)\n",
    "fig, ax = plt.subplots(2,2,figsize=(15,5))\n",
    "ax[0,0].plot(losses[:,0],label='reconst')\n",
    "ax[0,0].legend()\n",
    "ax[0,1].plot(losses[:,1],label='kl')\n",
    "ax[0,1].legend()\n",
    "ax[1,0].plot(losses[:,2],label='decoder')\n",
    "ax[1,0].legend()\n",
    "ax[1,1].plot(losses[:,3],label='latent')\n",
    "ax[1,1].legend()\n",
    "\n",
    "jnp.savez('params_vae_lat={}_kl={:.2e}.npz'.format(latent_dim, lambda_kl), params_vae=params_vae, bn_vae_state=bn_vae_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_vae, bn_vae_state = vae_init(jax.random.PRNGKey(seed), np.random.uniform(0, 1, (1,input_size,input_size,input_channels)), True)\n",
    "optimizer_vae = optax.radam(5e-4)\n",
    "opt_vae_state = optimizer_vae.init(params_vae)\n",
    "\n",
    "@jax.jit\n",
    "def loss_ae(params, bn_state, obs):\n",
    "\n",
    "    vq_output, bn_state = vae_apply_jit(params, bn_state, obs, True)\n",
    "    vq_loss = vq_output['vq_loss']\n",
    "    loss_reconst = vq_output['recon_error']\n",
    "    loss_reconst = loss_reconst/var\n",
    "\n",
    "    loss_latent = 0\n",
    "    loss_decoder = 0\n",
    "\n",
    "    return vq_loss + loss_reconst + loss_decoder + loss_latent, (vq_loss, loss_reconst, loss_decoder, loss_latent, bn_state)\n",
    "\n",
    "def update(params, opt_state, bn_state, obs, mask):\n",
    "    (loss, aux), grad = jax.value_and_grad(loss_ae, has_aux=True)(params, bn_state, obs, mask)\n",
    "    updates, new_opt_state = optimizer_vae.update(grad, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "    return new_params, new_opt_state, loss, aux\n",
    "\n",
    "update_jit = jax.jit(update)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for k in range(num_epochs):\n",
    "\n",
    "    idx = np.random.choice(len(obs), batch_size)\n",
    "    batch_obs = jnp.array(obs[idx])\n",
    "    params_vae, opt_vae_state, loss, aux = update_jit(params_vae, opt_vae_state, bn_vae_state, batch_obs)\n",
    "    vq_loss, loss_reconst, loss_decoder, loss_latent, bn_vae_state = aux\n",
    "    losses.append([loss_reconst.item(), vq_loss.item(), loss_decoder.item(), loss_latent.item(), loss.item()])\n",
    "\n",
    "losses = np.array(losses)\n",
    "fig, ax = plt.subplots(2,2,figsize=(15,5))\n",
    "ax[0,0].plot(losses[:,0],label='reconst')\n",
    "ax[0,0].legend()\n",
    "ax[0,1].plot(losses[:,1],label='vq')\n",
    "ax[0,1].legend()\n",
    "ax[1,0].plot(losses[:,2],label='decoder')\n",
    "ax[1,0].legend()\n",
    "ax[1,1].plot(losses[:,3],label='latent')\n",
    "ax[1,1].legend()\n",
    "\n",
    "jnp.savez('params_vqvae_lat={}_lambda={:.2e}.npz'.format(latent_dim, commitment_cost), params_vae=params_vae, bn_vae_state=bn_vae_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "num_epochs = 3000\n",
    "batch_size = 16\n",
    "seed = np.random.randint(100)\n",
    "filter_sizes = [16,32,64,128]\n",
    "input_channels = output_channels = 1\n",
    "\n",
    "latent_dim = 24\n",
    "lambda_kl = 3.6644894566489406e-07\n",
    "temp = 4.911724757502476\n",
    "prior =  0.005071067050815106\n",
    "num_classes = 2 \n",
    "final_activation = jax.jit(lambda s:s)\n",
    "\n",
    "def cat_vae(s, is_training, T):\n",
    "    return vae.CatVAE(input_size, latent_dim, num_classes, filter_sizes, output_channels, final_activation)(s, is_training, T)\n",
    "\n",
    "vae_init, vae_apply  = hk.without_apply_rng(hk.transform_with_state(cat_vae))\n",
    "vae_apply_jit = jax.jit(vae_apply, static_argnums=3)\n",
    "params_vae, bn_vae_state = vae_init(jax.random.PRNGKey(seed), np.random.uniform(0, 1, (1,input_size,input_size,input_channels)), True, temp)\n",
    "optimizer_vae = optax.radam(5e-4)\n",
    "opt_vae_state = optimizer_vae.init(params_vae)\n",
    "\n",
    "@jax.jit\n",
    "def loss_ae(params, bn_state, obs, T, eps = 1e-7):\n",
    "\n",
    "    aux, bn_state = vae_apply_jit(params, bn_state, obs, True, T)\n",
    "    reconst, latent, q = aux\n",
    "    q_p = jax.nn.softmax(q, axis=-1)\n",
    "\n",
    "    # MSE for reconstruction errors.\n",
    "    loss_reconst = jnp.square(obs - reconst).mean()\n",
    "    loss_reconst = loss_reconst/var\n",
    "\n",
    "    loss_decoder = 0\n",
    "    loss_latent = 0\n",
    "\n",
    "    h1 = q_p * jnp.log(q_p + eps)\n",
    "\n",
    "    # Cross entropy with the categorical distribution\n",
    "    h2 = q_p * jnp.log(prior + eps)\n",
    "    loss_kl = jnp.mean(jnp.sum(h1 - h2, axis =(1,2)), axis=0)\n",
    "    loss_kl = lambda_kl*loss_kl\n",
    "    \n",
    "    return loss_reconst + loss_kl + loss_decoder + loss_latent, (loss_reconst, loss_kl, loss_decoder, loss_latent, bn_state)\n",
    "\n",
    "def update(params, opt_state, bn_state, obs, T):\n",
    "\n",
    "    (loss, aux), grad = jax.value_and_grad(loss_ae, has_aux=True)(params, bn_state, obs, T)\n",
    "    updates, new_opt_state = optimizer_vae.update(grad, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "    return new_params, new_opt_state, loss, aux\n",
    "\n",
    "update_jit = jax.jit(update)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for k in range(1,num_epochs+1):\n",
    "    idx = np.random.choice(len(obs), batch_size)\n",
    "    batch_obs = jnp.array(obs[idx])\n",
    "    params_vae, opt_vae_state, loss, aux = update_jit(params_vae, opt_vae_state, bn_vae_state, batch_obs, temp)\n",
    "    loss_reconst, loss_kl, loss_decoder, loss_latent, bn_vae_state = aux\n",
    "    losses.append([loss_reconst.item(), loss_kl.item(), loss_decoder.item(), loss_latent.item(), loss.item()])\n",
    "\n",
    "losses = np.array(losses)\n",
    "fig, ax = plt.subplots(2,2,figsize=(15,5))\n",
    "ax[0,0].plot(losses[:,0],label='reconst')\n",
    "ax[0,0].legend()\n",
    "ax[0,1].plot(losses[:,1],label='kl')\n",
    "ax[0,1].legend()\n",
    "ax[1,0].plot(losses[:,2],label='decoder')\n",
    "ax[1,0].legend()\n",
    "ax[1,1].plot(losses[:,3],label='latent')\n",
    "ax[1,1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = jnp.load('/mnt/diskSustainability/frederic/sony_RL/params_vae_lat=14_kl=9.21e-05.npz', allow_pickle=True)\n",
    "params_vae = weights['params_vae'][()]\n",
    "bn_vae_state =  weights['bn_vae_state'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check reconstruction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "ts = env.step_angle(0.5, 0.1)\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].imshow(env.canny, cmap='gray')\n",
    "aux, _ = vae_apply_jit(params_vae, bn_vae_state, env.canny[None]*1., False)\n",
    "reconst, latent, mu, log_var = aux\n",
    "'''vq_output, _ = vae_apply_jit(params_vae, bn_vae_state, env.canny[None]*1., False)\n",
    "reconst = vq_output['x_recon']'''\n",
    "ax[1].imshow(reconst[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check interpretability of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = []\n",
    "pos = []\n",
    "imgs = []\n",
    "labels = np.concatenate(np.array([[theta]*100 for theta in np.linspace(np.pi/8,np.pi/2,15)]))\n",
    "labels_bokeh = []\n",
    "ts = env.reset()\n",
    "for theta in np.linspace(np.pi/8,np.pi/2,15):\n",
    "    for phi in np.linspace(0,2*np.pi,100):\n",
    "        ts = env.step_angle(theta, phi)\n",
    "        pos.append(env.pos)\n",
    "        vae_output, _ = vae_apply_jit(params_vae, bn_vae_state, env.canny[None]*1., False)\n",
    "        latent.append(vae_output[1][0])\n",
    "        imgs.append(env.canny[...,0])\n",
    "        x,y,z = env.pos\n",
    "        labels_bokeh.append('x={:.2f}, y={:.2f}'.format(x,y))\n",
    "        \n",
    "latent = np.array(latent)\n",
    "pos = np.array(pos)\n",
    "imgs = np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot\n",
    "embedding = umap.UMAP(n_neighbors=20, low_memory=False, n_jobs=-1).fit(latent)\n",
    "umap.plot.points(embedding, labels=np.around(labels,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "def embeddable_image(img):\n",
    "    image = Image.fromarray(img, mode='L')\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format='png')\n",
    "    for_encoding = buffer.getvalue()\n",
    "    return 'data:image/png;base64,' + base64.b64encode(for_encoding).decode()\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(embedding.transform(latent), columns=('x', 'y'))\n",
    "df['image'] = list(map(embeddable_image, imgs))\n",
    "df['pos'] = labels_bokeh\n",
    "datasource = ColumnDataSource(df)\n",
    "\n",
    "plot_figure = figure(\n",
    "    title='UMAP projection of the encoder output',\n",
    "    plot_width=600,\n",
    "    plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "'''plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <img src='@image' style='float: left; margin: 5px 5px 5px 5px'/>\n",
    "    </div>\n",
    "    \n",
    "</div>\n",
    "\"\"\"))'''\n",
    "\n",
    "plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <img src='@image' style='float: left; margin: 5px 5px 5px 5px'/>\n",
    "    </div>\n",
    "    <div>\n",
    "        <span style='font-size: 16px; color: #224499'>pos:</span>\n",
    "        <span style='font-size: 18px'>@pos</span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "plot_figure.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4\n",
    ")\n",
    "show(plot_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_path = '/mnt/diskSustainability/frederic/scanner-gym_models_v2/sphere_hole'\n",
    "object_name = 'sphere.obj'\n",
    "env = SphereEnv(objects_path, object_name, img_shape=128, voxel_weights=voxel_weights, rmax=0.7, continuous=True, use_img=True, max_T=50)\n",
    "env_test = SphereEnv(objects_path, object_name, img_shape=128, voxel_weights=voxel_weights, rmax=0.7, continuous=True, use_img=True, max_T=50)\n",
    "ts = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/diskSustainability/frederic/sony_RL/sony_RL/sac')\n",
    "from sac import SAC\n",
    "#from dqn import DQN\n",
    "from ddpg import DDPG\n",
    "from base_trainer import Trainer\n",
    "os.chdir(path)\n",
    "\n",
    "seed = np.random.randint(100)\n",
    "encoder = (vae_apply_jit, params_vae, bn_vae_state)\n",
    "'''agent = DQN(num_agent_steps=10**6, state_space=np.empty(env.observation_shape), action_space=np.array(list(env.actions.keys())), \n",
    "           seed=seed, start_steps=10**3, gamma=0.75, buffer_size=10**3, batch_size=32)\n",
    "'''\n",
    "\n",
    "agent = SAC(num_agent_steps=10**6, state_space=np.empty(env.observation_shape), action_space=np.empty((2,2)), \n",
    "             seed=seed, start_steps=10**3, gamma=0.75, buffer_size=10**3, batch_size=32, encoder=encoder, scale_reward=5)\n",
    "#agent.load_params('/mnt/diskSustainability/frederic/sony_RL/sac_beta_coordconv_vae_logs/param/step1000000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        env=env,\n",
    "        env_test=env_test,\n",
    "        algo=agent,\n",
    "        log_dir='sac_vae_scale=5_logs',\n",
    "        num_agent_steps=10**6,\n",
    "        action_repeat=1,\n",
    "        eval_interval=10**3,\n",
    "        save_params=True,\n",
    "        save_interval=10**4\n",
    "    )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check trajectories obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = env_test.reset()\n",
    "rewards = []\n",
    "for k in range (20):\n",
    "    action = agent.select_action(ts.observation)\n",
    "    ts = env_test.step(action)\n",
    "    rewards.append(ts.reward)\n",
    "    if ts.step_type == 2:\n",
    "        print('finished in {} steps'.format(k+1))\n",
    "        break\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.array(env_test.visited_positions)\n",
    "theta = angles[:,0]\n",
    "phi = angles[:,1]\n",
    "\n",
    "if not env_test.continuous:\n",
    "    theta = (theta+1)*np.pi/8\n",
    "    phi = phi*np.pi/90\n",
    "\n",
    "R = 5\n",
    "a = R*np.sin(theta)*np.cos(phi)\n",
    "b = R*np.sin(theta)*np.sin(phi)\n",
    "c = R*np.cos(theta)\n",
    "\n",
    "a = (a+4.97)/0.4\n",
    "b = (b+4.97)/0.4\n",
    "c = (c+4.97)/0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "l = []\n",
    "for i in range (len(a)):\n",
    "    l.append([i/len(a),'rgb'+str(plt.get_cmap('jet', len(a))(i,bytes=True)[:3])])\n",
    "    l.append([(i+1)/len(a),'rgb'+str(plt.get_cmap('jet', len(a))(i,bytes=True)[:3])])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=a,y=b,z=c,marker=dict(\n",
    "        color=np.arange(len(a)),\n",
    "        colorscale=l,                \n",
    "        colorbar=dict(thickness=20,title={\n",
    "        'text': 'Timesteps','side':'bottom'},\n",
    "           tick0=0,dtick=1,x=0.8, y=0.4, len=0.75)),\n",
    "        text=[str(k) for k in range(len(a))],hoverinfo='text',showlegend=False))\n",
    "fig.add_trace(go.Scatter3d(x=x[mask],y=y[mask],z=z[mask],mode='markers',showlegend=False))\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0),hovermode='closest', width=700, height=450,title={\n",
    "        'text': 'Trajectory using DQN',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'}\n",
    "           )\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
